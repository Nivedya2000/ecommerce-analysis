# ğŸ›’ E-Commerce Data Analysis with Databricks & PySpark

![Python](https://img.shields.io/badge/Python-3.x-blue?logo=python)
![Apache Spark](https://img.shields.io/badge/Apache_Spark-3.x-orange?logo=apachespark)
![Databricks](https://img.shields.io/badge/Databricks-Platform-red?logo=databricks)
![Delta Lake](https://img.shields.io/badge/Delta_Lake-Enabled-green?logo=databricks)
![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)

---

## ğŸ“Œ Project Overview
This project demonstrates how to process, analyze, and visualize **e-commerce transaction data** using **Databricks**, **PySpark**, and **SQL**.  

It covers the full pipeline:
- Data ingestion & preparation  
- Train/Test split (customer-level)  
- Exploratory Data Analysis (EDA)  
- Advanced analytics (Customer Segmentation, Time-Series Forecasting, Anomaly Detection)  

The dataset is stored in **Delta format**. The pipeline extracts insights about **customer behavior, country-level trends, product performance, and sales anomalies**.

---

## ğŸš€ Features
- âœ… **Dynamic catalog detection** (works across Community & Premium Databricks editions)  
- âœ… **Clean data preparation** â€“ build invoice & item tables  
- âœ… **Train/Test split** at customer-level to avoid leakage  
- âœ… **Exploratory Data Analysis (EDA)**:
  - Countries & customers  
  - Top products & revenue drivers  
  - Order volume trends  
  - Refund/negative price checks  
- âœ… **Advanced Analytics**:
  - RFM Segmentation + KMeans Clustering  
  - Monthly Sales Trend Forecasting  
  - Anomaly Detection in Invoice Revenue  
- âœ… **Interactive Visualizations** with Databricks `display()` and Matplotlib  

---

## ğŸ“‚ Project Structure
```
ecommerce-analysis/
â”‚â”€â”€ ecomm_databricks_pipeline.py   # Main Databricks pipeline script
â”‚â”€â”€ README.md                      # Project documentation
â”‚â”€â”€ LICENSE                        # License (MIT)
â”‚â”€â”€ .gitignore                     # Git ignore rules
```

---

## ğŸ› ï¸ Requirements
- **Databricks Runtime** (Spark 3.x + Delta support)  
- **Python 3.x**  
- Libraries:
  - PySpark (pre-installed in Databricks)  
  - Pandas  
  - Matplotlib  
  - scikit-learn (for clustering)  

---

## â–¶ï¸ How to Run
1. Upload `ecomm_databricks_pipeline.py` into your **Databricks workspace**.  
2. Ensure you have a Delta table named **`data_ecomm`** in your catalog (`hive_metastore.default` or `workspace.default`).  
3. Run cells in order:  
   - Load & prepare data  
   - Create `invoices` & `items` tables  
   - Verify tables  
   - Perform EDA & visualizations  
   - Run advanced analytics (clustering, forecasting, anomaly detection)  
4. Review insights in Databricks dashboards/plots.  

---

## ğŸ“Š Key Insights
- ğŸ‡¬ğŸ‡§ **UK dominates** in customer count & revenue.  
- ğŸ“¦ Certain products (e.g., decorative lanterns) dominate sales.  
- âš ï¸ Negative prices = refunds/returns.  
- ğŸ‘¥ **Customer segmentation** reveals distinct groups of buyers.  
- ğŸ“ˆ Monthly sales trends highlight seasonal demand.  
- ğŸš¨ Outliers in invoices may indicate fraud or data issues.  

---

## ğŸ”® Future Enhancements
- Customer churn prediction  
- Product recommendation system  
- Dashboard integration (Tableau / Power BI)  
- Pipeline automation with scheduled Databricks jobs  

---

## ğŸ‘©â€ğŸ’» Author
Developed by **Nivedya K**  
ğŸ“§ [Email](mailto:nivedyak1112@gmail.com) | ğŸ”— [LinkedIn](https://linkedin.com/in/nivedya-k) | ğŸ™ [GitHub](https://github.com/Nivedya2000)

---

## ğŸ“œ License
This project is licensed under the **MIT License** â€“ see the [LICENSE](LICENSE) file for details.
