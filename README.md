# ğŸ›’ E-Commerce Data Analysis with Databricks & PySpark

![Python](https://img.shields.io/badge/Python-3.x-blue?logo=python)
![Apache Spark](https://img.shields.io/badge/Apache_Spark-3.x-orange?logo=apachespark)
![Databricks](https://img.shields.io/badge/Databricks-Platform-red?logo=databricks)
![Delta Lake](https://img.shields.io/badge/Delta_Lake-Enabled-green?logo=databricks)

---

## ğŸ“Œ Project Overview
This project demonstrates how to process, analyze, and visualize **e-commerce transaction data** using **Databricks**, **PySpark**, and **SQL**.  
It covers the full pipeline: data preparation, train/test split, and exploratory data analysis (EDA).  

The dataset is stored in Databricks Delta format, and the analysis includes country-level insights, customer behavior, product trends, and revenue breakdowns.

---

## ğŸš€ Features
- âœ… **Dynamic catalog detection** â€“ works across Community & Premium Databricks editions  
- âœ… **Data preparation** â€“ clean invoice & item tables from raw data  
- âœ… **Train/Test split** â€“ customer-level splitting to prevent data leakage  
- âœ… **Exploratory Data Analysis (EDA)**:
  - Number of countries
  - Top countries by customers
  - Top customers by order volume
  - Most frequently ordered items
  - Price distribution (+ check for negative prices)
  - Revenue-generating items (inside vs. outside UK)
  - Customers who purchased specific products (e.g., *WHITE METAL LANTERN*)  
- âœ… **Visualizations** using Databricks `display()` and Matplotlib  

---

## ğŸ“‚ Project Structure
â”œâ”€â”€ databricks_ecomm_pipeline.py 
â”œâ”€â”€ README.md 

---

## ğŸ› ï¸ Requirements
- **Databricks Runtime** (with Spark 3.x + Delta support)  
- **Python 3.x**  
- **Libraries:**
  - PySpark (pre-installed on Databricks)
  - Pandas
  - Matplotlib

---

## â–¶ï¸ How to Run
1. Upload `databricks_ecomm_pipeline.py` into your Databricks workspace.  
2. Ensure you have a Delta table named `data_ecomm` in your catalog (`hive_metastore.default` or `workspace.default`).  
3. Run the notebook cells step by step:  
   - Load and prepare data  
   - Create invoice and item tables  
   - Verify data  
   - Train/test split  
   - Perform exploratory queries and visualizations  
4. Review insights in Databricks dashboards or plots.  

---

## ğŸ“Š Key Insights
- The UK contributes the highest number of customers and revenue.  
- Some items (e.g., decorative lanterns) dominate sales volume.  
- Negative prices exist in the dataset (likely returns/refunds).  
- Customer-level splitting ensures no data leakage when preparing ML models.  

---

## ğŸ”® Future Work
- Customer segmentation using clustering (RFM analysis).  
- Time-series forecasting for sales by product or country.  
- Anomaly detection for unusual transactions (e.g., negative prices).  

---

## ğŸ‘©â€ğŸ’» Author
Developed by **[Nivedya K]**  
Feel free to connect and collaborate ğŸš€
# ecommerce-analysis
